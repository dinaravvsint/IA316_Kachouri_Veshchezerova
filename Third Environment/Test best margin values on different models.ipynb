{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test best margin on models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input similarities are not normalized $\\in \\{0, 4\\}$. So we will test these margin values to fond the best for each model : $\\{0.5, 1, 1.5, 2, 2.5, 3, 3.5\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "margins = [0.5,1,1.5,2,2.5,3,3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import requests \n",
    "from time import sleep\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten, Input, Dense, Dropout, Concatenate, Lambda, Dot\n",
    "\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LightFM + Siamese model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "from lightfm import LightFM\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Useful Functions predefined\n",
    "%run useful_functions_modified.py\n",
    "from useful_functions_modified import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Model : only ids without new users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['nb_items', 'nb_users', 'action_history', 'rewards_history', 'state_history', 'next_state'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = '0H3BRZ9M0BQP3SFPSCL3'\n",
    "base_url ='http://35.180.178.243/'\n",
    "url_reset = base_url+\"reset\"\n",
    "url_predict = base_url+'predict'\n",
    "params = {'user_id':user_id}\n",
    "r = requests.get(url=url_reset,params=params) # get history of rating\n",
    "data = r.json()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users, nb_items = data['nb_users'], data['nb_items']\n",
    "\n",
    "action_history, state_history, rewards_history = data['action_history'], data['state_history'], data['rewards_history']\n",
    "next_state = data['next_state']\n",
    "\n",
    "users_ids = list(zip(*list(list(zip(*state_history))[0])))[0]\n",
    "pos_rewards = compute_pos_rewards(rewards_history)\n",
    "pos_data = create_pos_data(pos_rewards,state_history,action_history)\n",
    "\n",
    "nb_iters, n_epochs = 1000, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building models for different margins...\n",
      "\tBuild model for margin =  0.5\n",
      "\tBuild model for margin =  1\n",
      "\tBuild model for margin =  1.5\n",
      "\tBuild model for margin =  2\n",
      "\tBuild model for margin =  2.5\n",
      "\tBuild model for margin =  3\n",
      "\tBuild model for margin =  3.5\n",
      "Finisht building models.\n"
     ]
    }
   ],
   "source": [
    "print(\"Start building models for different margins...\")\n",
    "for ma in margins:\n",
    "    print(\"\\tBuild model for margin = \", ma)\n",
    "    def margin_comparator_loss_(inputs, margin=ma):\n",
    "        positive_pair_sim, negative_pair_sim = inputs\n",
    "        return tf.maximum(negative_pair_sim - positive_pair_sim + margin, 0)\n",
    "\n",
    "    rewards = 0\n",
    "    nb_reward_pos=0\n",
    "    deep_match_model, deep_triplet_model = build_models(nb_users, nb_items, user_dim=32,\n",
    "                                                    item_dim= 15, n_hidden =2, hidden_size=64,\n",
    "                                                    dropout=0.1,l2_reg=0,loss=margin_comparator_loss_)\n",
    "    deep_triplet_model.compile(loss=identity_loss, optimizer='adam')\n",
    "    fake_y = np.ones_like(pos_data['user_id'])\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        # Sample new negatives to build different triplets at each epoch\n",
    "        triplet_inputs = sample_triplets(pos_data,random_seed=i)\n",
    "        # Fit the model incrementally by doing a single pass over the\n",
    "        # sampled triplets.\n",
    "        deep_triplet_model.fit(triplet_inputs, fake_y, shuffle=True, batch_size=32, epochs=1, verbose=0)\n",
    "    models.append(deep_match_model)\n",
    "print(\"Finisht building models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAverage reward:  132.82349842332832========================>|95%\n",
      "\tPercentage of positive rewards:  33.4 %\n",
      "\tAverage reward:  115.27638840276973======================>|95%\n",
      "\tPercentage of positive rewards:  32.7 %\n",
      "\tAverage reward:  154.3926711921762=========================>|95%\n",
      "\tPercentage of positive rewards:  30.9 %\n",
      "\tAverage reward:  119.7954770912971=======================>|95%\n",
      "\tPercentage of positive rewards:  27.900000000000002 %\n",
      "\tAverage reward:  123.47391156653173========================>|95%\n",
      "\tPercentage of positive rewards:  23.1 %\n",
      "\tAverage reward:  137.85805247163256======================>|95%\n",
      "\tPercentage of positive rewards:  25.8 %\n",
      "\tAverage reward:  129.54683952594434========================>|95%\n",
      "\tPercentage of positive rewards:  23.3 %\n"
     ]
    }
   ],
   "source": [
    "for margin, model in zip(margins, models):\n",
    "    rewards, nb_reward_pos = 0, 0\n",
    "    k, max_k = 0, int(nb_iters / 50) # index just to print progrees\n",
    "    s = 'Test for margin: ' + str(margin)\n",
    "    for i in range(nb_iters):  \n",
    "        if i % 50 == 0:\n",
    "            end_ln = \"\\r\" if i != (nb_iters-1) else \"\\n\"\n",
    "            print(s + \"\\t|\" + k * \"==\" +\">\"+ (max_k - k - 1) * \"--\" +\"|\" + str(int(i * 100/nb_iters)) + \"%\", end=end_ln)\n",
    "            k += 1\n",
    "        sleep(0.05) # sleep to let the API breathe and allow others to call requests\n",
    "        next_user = np.asarray([next_state[0][0] for i in range(len(next_state))])\n",
    "        list_items = np.asarray(list(list(zip(*next_state))[1]))\n",
    "\n",
    "        predictions = model.predict([next_user, list_items])\n",
    "        recommended_item = np.argmax(predictions)\n",
    "\n",
    "        params['recommended_item'] = recommended_item \n",
    "        r=requests.get(url=url_predict,params=params)\n",
    "        d=r.json()\n",
    "        reward= d['reward'] # previous reward for the recommended item predicted\n",
    "\n",
    "        # check how many times the item recommended was actually bought\n",
    "        if reward > 0 : \n",
    "            nb_reward_pos+=1\n",
    "\n",
    "        next_state = d['state']\n",
    "        rewards += reward\n",
    "\n",
    "    print('\\tAverage reward: ', rewards/nb_iters)\n",
    "    print('\\tPercentage of positive rewards: ', 100*(nb_reward_pos/nb_iters), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{array}{|c|c|c|} \\hline\n",
    "   \\textbf{margin} & \\textbf{avg reward} & \\textbf{% of postitve} \\\\ \\hline\n",
    "   0.5 & 132.82349842332832 & \\textbf{33.4} \\\\ \n",
    "   1   & 115.27638840276973 & 32.7 \\\\\n",
    "   1.5 & \\textbf{154.3926711921762} &  30.9  \\\\\n",
    "   2   & 119.7954770912971  & 27.9 \\\\\n",
    "   2.5 & 123.47391156653173 & 23.1 \\\\\n",
    "   3   & 137.85805247163256 & 25.8  \\\\\n",
    "   3.5 & 129.54683952594434 & 23.3  \\\\ \\hline\n",
    "\\end{array} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Model : adding coavariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url=url_reset,params=params) # get history of rating\n",
    "data = r.json()\n",
    "nb_users, nb_items = data['nb_users'], data['nb_items']\n",
    "\n",
    "action_history, state_history, rewards_history = data['action_history'], data['state_history'], data['rewards_history']\n",
    "next_state = data['next_state']\n",
    "\n",
    "users_ids = list(zip(*list(list(zip(*state_history))[0])))[0]\n",
    "pos_rewards = compute_pos_rewards(rewards_history)\n",
    "pos_data = create_pos_data(pos_rewards,state_history,action_history)\n",
    "\n",
    "nb_iters, n_epochs = 1000, 50\n",
    "models2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building models for different margins...\n",
      "\tBuild model for margin =  0.5\n",
      "\tBuild model for margin =  1\n",
      "\tBuild model for margin =  1.5\n",
      "\tBuild model for margin =  2\n",
      "\tBuild model for margin =  2.5\n",
      "\tBuild model for margin =  3\n",
      "\tBuild model for margin =  3.5\n",
      "Finisht building models.\n"
     ]
    }
   ],
   "source": [
    "print(\"Start building models for different margins...\")\n",
    "for ma in margins:\n",
    "    print(\"\\tBuild model for margin = \", ma)\n",
    "    def margin_comparator_loss_(inputs, margin=ma):\n",
    "        positive_pair_sim, negative_pair_sim = inputs\n",
    "        return tf.maximum(negative_pair_sim - positive_pair_sim + margin, 0)\n",
    "\n",
    "    deep_match_model2, deep_triplet_model2 = build_models_covariates(nb_users, nb_items, user_dim=32,\n",
    "                                                                item_dim= 15, n_hidden =2, hidden_size=64,\n",
    "                                                                dropout=0.1,l2_reg=0,loss=margin_comparator_loss_)\n",
    "    deep_triplet_model2.compile(loss=identity_loss, optimizer='adam')\n",
    "    fake_y = np.ones_like(pos_data['user_id'])\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        # Sample new negatives to build different triplets at each epoch\n",
    "        inputs = sample_quintuplets(pos_data,state_history, random_seed=i)\n",
    "    \n",
    "        # Fit the model incrementally by doing a single pass over the sampled quintuplets.\n",
    "        deep_triplet_model2.fit(inputs, fake_y, shuffle=True, batch_size=32, epochs=1, verbose=0)\n",
    "    models2.append(deep_match_model2)\n",
    "print(\"Finisht building models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for margin: 0.5\t|======================================>|95%\n",
      "\tAverage reward:  91.20541694875492\n",
      "\tPercentage of positive rewards:  20.8 %\n",
      "Test for margin: 1\t|======================================>|95%\n",
      "\tAverage reward:  169.34868136789063\n",
      "\tPercentage of positive rewards:  31.2 %\n",
      "Test for margin: 1.5\t|======================================>|95%\n",
      "\tAverage reward:  86.15808849619859\n",
      "\tPercentage of positive rewards:  30.099999999999998 %\n",
      "Test for margin: 2\t|======================================>|95%\n",
      "\tAverage reward:  59.38050090655821\n",
      "\tPercentage of positive rewards:  22.6 %\n",
      "Test for margin: 2.5\t|======================================>|95%\n",
      "\tAverage reward:  93.63423404862137\n",
      "\tPercentage of positive rewards:  23.400000000000002 %\n",
      "Test for margin: 3\t|======================================>|95%\n",
      "\tAverage reward:  99.31253386815727\n",
      "\tPercentage of positive rewards:  24.9 %\n",
      "Test for margin: 3.5\t|======================================>|95%\n",
      "\tAverage reward:  129.38822175934718\n",
      "\tPercentage of positive rewards:  23.0 %\n"
     ]
    }
   ],
   "source": [
    "for margin, model in zip(margins, models2):\n",
    "    rewards, nb_reward_pos = 0, 0\n",
    "    k, max_k = 0, int(nb_iters / 50) # index just to print progrees\n",
    "    s = 'Test for margin: ' + str(margin)\n",
    "    end_ln = \"\\r\"\n",
    "    for i in range(nb_iters): \n",
    "        if i % 50 == 0:\n",
    "            if (max_k - k - 1 == 0): end_ln = \"\\n\"\n",
    "            print(s + \"\\t|\" + k * \"==\" +\">\"+ (max_k - k - 1) * \"--\" +\"|\" + str(int(i * 100/nb_iters)) + \"%\", end=end_ln)\n",
    "            k += 1\n",
    "        sleep(0.05) # sleep to let the API breathe and allow others to call requests\n",
    "        next_user = np.asarray([next_state[0][0] for i in range(len(next_state))])\n",
    "        list_items = np.asarray(list(list(zip(*next_state))[1]))\n",
    "        list_feat_user = np.expand_dims(np.asarray([next_state[0][3:5] for i in range(len(next_state))]), axis=1)\n",
    "        list_feat_items = np.expand_dims(np.asarray([next_state[0][5:-1] for i in range(len(next_state))]), axis=1)\n",
    "\n",
    "        predictions = model.predict([next_user, list_items, list_feat_user, list_feat_items])\n",
    "        recommended_item = np.argmax(predictions)\n",
    "\n",
    "        params['recommended_item'] = recommended_item \n",
    "        r=requests.get(url=url_predict,params=params)\n",
    "        d=r.json()\n",
    "        reward= d['reward'] # previous reward for the recommended item predicted\n",
    "\n",
    "        # check how many times the item recommended was actually bought\n",
    "        if reward > 0 : \n",
    "            nb_reward_pos+=1\n",
    "\n",
    "        next_state = d['state']\n",
    "        rewards += reward\n",
    "    print('\\tAverage reward: ', rewards/nb_iters)\n",
    "    print('\\tPercentage of positive rewards: ', 100*(nb_reward_pos/nb_iters), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{array}{|c|c|c|} \\hline\n",
    "   \\textbf{margin} & \\textbf{avg reward} & \\textbf{% of postitve} \\\\ \\hline\n",
    "   0.5 & 91.20541694875492 & 20.8 \\\\ \n",
    "   1   & \\textbf{169.34868136789063} & \\textbf{31.2} \\\\\n",
    "   1.5 & 86.15808849619859 & 30.09  \\\\\n",
    "   2   & 59.38050090655821 & 22.6 \\\\\n",
    "   2.5 & 93.63423404862137 & 23.40 \\\\\n",
    "   3   & 99.31253386815727 & 24.9  \\\\\n",
    "   3.5 & 129.38822175934718 & 23.0  \\\\ \\hline\n",
    "\\end{array} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd Model : Tackling Cold Start Issue (e.g New Users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url=url_reset,params=params) # get history of rating\n",
    "data = r.json()\n",
    "nb_users, nb_items = data['nb_users'], data['nb_items']\n",
    "\n",
    "action_history, state_history, rewards_history = data['action_history'], data['state_history'], data['rewards_history']\n",
    "next_state = data['next_state']\n",
    "\n",
    "users_ids = list(zip(*list(list(zip(*state_history))[0])))[0]\n",
    "pos_rewards = compute_pos_rewards(rewards_history)\n",
    "pos_data = create_pos_data(pos_rewards,state_history,action_history)\n",
    "\n",
    "nb_iters, nb_epochs = 1000, 50\n",
    "models3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building models for different margins...\n",
      "\tBuild model for margin =  0.5\n",
      "\tBuild model for margin =  1\n",
      "\tBuild model for margin =  1.5\n",
      "\tBuild model for margin =  2\n",
      "\tBuild model for margin =  2.5\n",
      "\tBuild model for margin =  3\n",
      "\tBuild model for margin =  3.5\n",
      "Finisht building models.\n"
     ]
    }
   ],
   "source": [
    "print(\"Start building models for different margins...\")\n",
    "for ma in margins:\n",
    "    print(\"\\tBuild model for margin = \", ma)\n",
    "    def margin_comparator_loss_(inputs, margin=ma):\n",
    "        positive_pair_sim, negative_pair_sim = inputs\n",
    "        return tf.maximum(negative_pair_sim - positive_pair_sim + margin, 0)\n",
    "\n",
    "    deep_match_model3, deep_triplet_model3 = build_models_covariates(nb_users, nb_items, user_dim=32,\n",
    "                                                                item_dim= 15, n_hidden =2, hidden_size=64,\n",
    "                                                                dropout=0.1,l2_reg=0,loss=margin_comparator_loss_)\n",
    "    deep_triplet_model3.compile(loss=identity_loss, optimizer='adam')\n",
    "    fake_y = np.ones_like(pos_data['user_id'])\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        # Sample new negatives to build different triplets at each epoch\n",
    "        inputs = sample_quintuplets(pos_data,state_history, random_seed=i)\n",
    "    \n",
    "        # Fit the model incrementally by doing a single pass over the sampled quintuplets.\n",
    "        deep_triplet_model3.fit(inputs, fake_y, shuffle=True, batch_size=32, epochs=1, verbose=0)\n",
    "    models3.append(deep_match_model2)\n",
    "print(\"Finisht building models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for margin: 0.5\t|========================================>|99%\n",
      "\tAverage reward:  117.42578061727096\n",
      "\tPercentage of positive rewards:  19.7 %\n",
      "Test for margin: 1\t|========================================>|99%\n",
      "\tAverage reward:  121.62543696438043\n",
      "\tPercentage of positive rewards:  24.9 %\n",
      "Test for margin: 1.5\t|========================================>|99%\n",
      "\tAverage reward:  169.73302930663246\n",
      "\tPercentage of positive rewards:  28.1 %\n",
      "Test for margin: 2\t|========================================>|99%\n",
      "\tAverage reward:  113.18605313848596\n",
      "\tPercentage of positive rewards:  24.0 %\n",
      "Test for margin: 2.5\t|========================================>|99%\n",
      "\tAverage reward:  111.52637722525041\n",
      "\tPercentage of positive rewards:  17.8 %\n",
      "Test for margin: 3\t|========================================>|99%\n",
      "\tAverage reward:  87.66752154725002\n",
      "\tPercentage of positive rewards:  18.8 %\n",
      "Test for margin: 3.5\t|========================================>|99%\n",
      "\tAverage reward:  107.42923167915677\n",
      "\tPercentage of positive rewards:  19.2 %\n"
     ]
    }
   ],
   "source": [
    "for margin, model in zip(margins, models2):\n",
    "    rewards, nb_reward_pos = 0, 0\n",
    "    k, max_k = 0, int(nb_iters / 50) # index just to print progrees\n",
    "    s = 'Test for margin: ' + str(margin)\n",
    "    end_ln = \"\\r\"\n",
    "    for i in range(nb_iters): \n",
    "        if i % 50 == 0 or i == (nb_iters - 1):\n",
    "            if i == (nb_iters - 1) : end_ln = \"\\n\"\n",
    "            print(s + \"\\t|\" + k * \"==\" +\">\"+ (max_k - k - 1) * \"--\" +\"|\" + str(int(i * 100/nb_iters)) + \"%\", end=end_ln)\n",
    "            k += 1\n",
    "        sleep(0.05) # sleep to let the API breathe and allow others to call requests\n",
    "        if next_state[0][0] in pos_data.user_id.unique().tolist():\n",
    "            next_user = np.asarray([next_state[0][0] for i in range(len(next_state))])\n",
    "            list_feat_user = np.expand_dims(np.asarray([next_state[0][3:5] for i in range(len(next_state))]), axis=1)\n",
    "        else:\n",
    "            #predict items based on users' profile similarity \n",
    "            most_similar_user_id = compute_most_similar(state_history,next_state,pos_data) \n",
    "            next_user = np.asarray([most_similar_user_id for i in range(len(next_state))])\n",
    "            list_feat_user = list(pos_data.loc[pos_data.user_id==most_similar_user_id,'feat_users'])[0]\n",
    "            list_feat_user = np.expand_dims(np.asarray([list_feat_user for i in range(len(next_state))]), axis=1)\n",
    "\n",
    "        list_items = np.asarray(list(list(zip(*next_state))[1]))\n",
    "        list_feat_items = np.expand_dims(np.asarray([next_state[0][5:-1] for i in range(len(next_state))]), axis=1)\n",
    "\n",
    "        predictions = model.predict([next_user, list_items, list_feat_user, list_feat_items])\n",
    "        recommended_item = np.argmax(predictions)\n",
    "\n",
    "        params['recommended_item'] = recommended_item \n",
    "        r=requests.get(url=url_predict,params=params)\n",
    "        d=r.json()\n",
    "        reward= d['reward'] # previous reward for the recommended item predicted\n",
    "\n",
    "        # check how many times the item recommended was actually bought\n",
    "        if reward > 0 : \n",
    "            nb_reward_pos+=1\n",
    "\n",
    "        next_state = d['state']\n",
    "        rewards += reward\n",
    "    print('\\tAverage reward: ', rewards/nb_iters)\n",
    "    print('\\tPercentage of positive rewards: ', 100*(nb_reward_pos/nb_iters), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{array}{|c|c|c|} \\hline\n",
    "   \\textbf{margin} & \\textbf{avg reward} & \\textbf{% of postitve} \\\\ \\hline\n",
    "   0.5 & 117.42578061727096 & 19.7  \\\\ \n",
    "   1   & 121.62543696438043 & 24.9 \\\\\n",
    "   1.5 & \\textbf{169.73302930663246} & \\textbf{28.1}  \\\\\n",
    "   2   & 113.18605313848596 & 24.0 \\\\\n",
    "   2.5 & 111.52637722525041 & 17.8 \\\\\n",
    "   3   & 87.66752154725002 & 18.8  \\\\\n",
    "   3.5 & 107.42923167915677 & 19.2  \\\\ \\hline\n",
    "\\end{array} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4rth Model : Model 3 + Adding Price in Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url=url_reset,params=params) # get history of rating\n",
    "data = r.json()\n",
    "nb_users, nb_items = data['nb_users'], data['nb_items']\n",
    "\n",
    "action_history, state_history, rewards_history = data['action_history'], data['state_history'], data['rewards_history']\n",
    "next_state = data['next_state']\n",
    "\n",
    "users_ids = list(zip(*list(list(zip(*state_history))[0])))[0]\n",
    "pos_rewards = compute_pos_rewards(rewards_history)\n",
    "pos_data = create_pos_data(pos_rewards,state_history,action_history)\n",
    "\n",
    "nb_iters, nb_epochs = 1000, 50\n",
    "models4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building models for different margins...\n",
      "\tBuild model for margin =  0.5\n",
      "\tBuild model for margin =  1\n",
      "\tBuild model for margin =  1.5\n",
      "\tBuild model for margin =  2\n",
      "\tBuild model for margin =  2.5\n",
      "\tBuild model for margin =  3\n",
      "\tBuild model for margin =  3.5\n",
      "Finisht building models.\n"
     ]
    }
   ],
   "source": [
    "print(\"Start building models for different margins...\")\n",
    "for ma in margins:\n",
    "    print(\"\\tBuild model for margin = \", ma)\n",
    "    def margin_comparator_loss_(inputs, margin=ma):\n",
    "        positive_pair_sim, negative_pair_sim = inputs\n",
    "        return tf.maximum(negative_pair_sim - positive_pair_sim + margin, 0)\n",
    "\n",
    "    deep_match_model4, deep_triplet_model4 = build_models_covariates_price(nb_users, nb_items, user_dim=32,\n",
    "                                                                        item_dim= 15, n_hidden =2, hidden_size=64,\n",
    "                                                                        dropout=0.1,l2_reg=0,loss=margin_comparator_loss_)\n",
    "    deep_triplet_model4.compile(loss=identity_loss, optimizer='adam')\n",
    "    fake_y = np.ones_like(pos_data['user_id'])\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        # Sample new negatives to build different triplets at each epoch\n",
    "        inputs = sample_quintuplets_price(pos_data,state_history, random_seed=i)\n",
    "    \n",
    "        # Fit the model incrementally by doing a single pass over the sampled quintuplets.\n",
    "        deep_triplet_model4.fit(inputs, fake_y, shuffle=True, batch_size=32, epochs=1, verbose=0)\n",
    "    models4.append(deep_match_model2)\n",
    "print(\"Finisht building models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for margin: 0.5\t|======================================>|95%\n",
      "\tAverage reward:  157.17093943610718\n",
      "\tPercentage of positive rewards:  34.300000000000004 %\n",
      "Test for margin: 1\t|======================================>|95%\n",
      "\tAverage reward:  150.76404292177008\n",
      "\tPercentage of positive rewards:  28.199999999999996 %\n",
      "Test for margin: 1.5\t|======================================>|95%\n",
      "\tAverage reward:  121.38626228014208\n",
      "\tPercentage of positive rewards:  22.6 %\n",
      "Test for margin: 2\t|======================================>|95%\n",
      "\tAverage reward:  98.01896432391887\n",
      "\tPercentage of positive rewards:  19.2 %\n",
      "Test for margin: 2.5\t|======================================>|95%\n",
      "\tAverage reward:  80.01904241963929\n",
      "\tPercentage of positive rewards:  16.8 %\n",
      "Test for margin: 3\t|======================================>|95%\n",
      "\tAverage reward:  78.6337802661393\n",
      "\tPercentage of positive rewards:  18.5 %\n",
      "Test for margin: 3.5\t|======================================>|95%\n",
      "\tAverage reward:  95.7018348709514\n",
      "\tPercentage of positive rewards:  22.900000000000002 %\n"
     ]
    }
   ],
   "source": [
    "for margin, model in zip(margins, models2):\n",
    "    rewards, nb_reward_pos = 0, 0\n",
    "    mean,std = compute_price_norm(state_history)\n",
    "    k, max_k = 0, int(nb_iters / 50) # index just to print progrees\n",
    "    s = 'Test for margin: ' + str(margin)\n",
    "    end_ln = \"\\r\"\n",
    "    for i in range(nb_iters): \n",
    "        if i % 50 == 0:\n",
    "            if (max_k - k - 1 == 0): end_ln = \"\\n\"\n",
    "            print(s + \"\\t|\" + k * \"==\" +\">\"+ (max_k - k - 1) * \"--\" +\"|\" + str(int(i * 100/nb_iters)) + \"%\", end=end_ln)\n",
    "            k += 1\n",
    "        sleep(0.05) # sleep to let the API breathe and allow others to call requests\n",
    "\n",
    "        list_items = np.asarray(list(list(zip(*next_state))[1]))\n",
    "        if next_state[0][0] in pos_data.user_id.unique().tolist():\n",
    "            next_user = np.asarray([next_state[0][0] for i in range(len(next_state))])\n",
    "            list_feat_user = np.expand_dims(np.asarray([next_state[0][3:5] for i in range(len(next_state))]), axis=1)\n",
    "        else:\n",
    "            #predict items based on users' profile similarity \n",
    "            most_similar_user_id = compute_most_similar(state_history,next_state,pos_data) \n",
    "            next_user = np.asarray([most_similar_user_id for i in range(len(next_state))])\n",
    "            list_feat_user = list(pos_data.loc[pos_data.user_id==most_similar_user_id,'feat_users'])[0]\n",
    "            list_feat_user = np.expand_dims(np.asarray([list_feat_user for i in range(len(next_state))]), axis=1)\n",
    "\n",
    "\n",
    "        prices =list(list(zip(*next_state))[1])\n",
    "        feat_items = [next_state[0][5:-1] for i in range(len(next_state))]\n",
    "        prices_norm = [(price-mean)/std for price in prices ] \n",
    "\n",
    "        for i,feature in  enumerate(feat_items):\n",
    "            feature.append(prices_norm[i])\n",
    "\n",
    "        list_feat_items = np.expand_dims(np.asarray(feat_items), axis=1)\n",
    "\n",
    "        predictions = deep_match_model4.predict([next_user, list_items, list_feat_user, list_feat_items])\n",
    "        recommended_item = np.argmax(predictions) # position item \n",
    "\n",
    "        params['recommended_item'] = recommended_item \n",
    "        r=requests.get(url=url_predict,params=params)\n",
    "        d=r.json()\n",
    "        reward= d['reward'] # previous reward for the recommended item predicted\n",
    "\n",
    "        # check how many times the item recommended was actually bought\n",
    "        if reward > 0 : \n",
    "            nb_reward_pos+=1\n",
    "\n",
    "        next_state = d['state']\n",
    "        rewards += reward\n",
    "    print('\\tAverage reward: ', rewards/nb_iters)\n",
    "    print('\\tPercentage of positive rewards: ', 100*(nb_reward_pos/nb_iters), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{array}{|c|c|c|} \\hline\n",
    "   \\textbf{margin} & \\textbf{avg reward} & \\textbf{% of postitve} \\\\ \\hline\n",
    "   0.5 & \\textbf{157.17093943610718} & \\textbf{34.30}  \\\\ \n",
    "   1   & 150.76404292177008 & 28.19 \\\\\n",
    "   1.5 & 121.38626228014208 & 22.6  \\\\\n",
    "   2   & 98.01896432391887 & 19.2 \\\\\n",
    "   2.5 & 80.01904241963929 & 16.8 \\\\\n",
    "   3   & 78.6337802661393 & 18.5  \\\\\n",
    "   3.5 & 95.7018348709514 & 22.90  \\\\ \\hline\n",
    "\\end{array} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hybrid : LightFM + Covariates / Cold Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '0H3BRZ9M0BQP3SFPSCL3'\n",
    "r = requests.get(url=url_reset,params=params) # get history of rating\n",
    "data = r.json()\n",
    "nb_users, nb_items = data['nb_users'], data['nb_items']\n",
    "\n",
    "action_history, state_history, rewards_history = data['action_history'], data['state_history'], data['rewards_history']\n",
    "next_state = data['next_state']\n",
    "\n",
    "users_ids = list(zip(*list(list(zip(*state_history))[0])))[0]\n",
    "pos_rewards = compute_pos_rewards(rewards_history)\n",
    "pos_data = create_pos_data(pos_rewards,state_history,action_history)\n",
    "\n",
    "nb_iters, nb_epochs = 1000, 50\n",
    "models5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_users, dict_items = {}, {}\n",
    "for i,j in enumerate(pos_data['user_id']):\n",
    "    dict_users[j] = i\n",
    "for i,j in enumerate(pos_data['item_id']):\n",
    "    dict_items[j] = i\n",
    "rows = [dict_users[i] for i in pos_data['user_id']]\n",
    "columns = [dict_items[i] for i in pos_data['item_id']]\n",
    "\n",
    "M,N = np.max(rows), np.max(columns)\n",
    "c = csr_matrix((np.ones((len(pos_data))), (rows, columns)), shape=(M+1, N+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x2265089c978>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_threads, nb_components, nb_epochs, alpha = 2, 30, 60, 1e-5\n",
    "\n",
    "# Let's fit a WARP model: these generally have the best performance.\n",
    "model_lightFM = LightFM(loss='warp',learning_schedule='adagrad',item_alpha=alpha,no_components=nb_components)\n",
    "model_lightFM.fit(c, epochs=nb_epochs, num_threads=nb_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building models for different margins...\n",
      "\tBuild model for margin =  0.5\n",
      "\tBuild model for margin =  1\n",
      "\tBuild model for margin =  1.5\n",
      "\tBuild model for margin =  2\n",
      "\tBuild model for margin =  2.5\n",
      "\tBuild model for margin =  3\n",
      "\tBuild model for margin =  3.5\n",
      "Finisht building models.\n"
     ]
    }
   ],
   "source": [
    "print(\"Start building models for different margins...\")\n",
    "for ma in margins:\n",
    "    print(\"\\tBuild model for margin = \", ma)\n",
    "    def margin_comparator_loss_(inputs, margin=ma):\n",
    "        positive_pair_sim, negative_pair_sim = inputs\n",
    "        return tf.maximum(negative_pair_sim - positive_pair_sim + margin, 0)\n",
    "    \n",
    "    \n",
    "\n",
    "    deep_match_model5, deep_triplet_model5 = build_models_covariates_price(nb_users, nb_items, user_dim=32,\n",
    "                                                                        item_dim= 15, n_hidden =2, hidden_size=64,\n",
    "                                                                        dropout=0.1,l2_reg=0,loss=margin_comparator_loss_)\n",
    "    deep_triplet_model5.compile(loss=identity_loss, optimizer='adam')\n",
    "    fake_y = np.ones_like(pos_data['user_id'])\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        # Sample new negatives to build different triplets at each epoch\n",
    "        inputs = sample_quintuplets_price(pos_data,state_history, random_seed=i)\n",
    "    \n",
    "        # Fit the model incrementally by doing a single pass over the sampled quintuplets.\n",
    "        deep_triplet_model5.fit(inputs, fake_y, shuffle=True, batch_size=32, epochs=1, verbose=0)\n",
    "    models4.append(deep_match_model2)\n",
    "print(\"Finisht building models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for margin: 0.5\t|======================================>|95%\n",
      "\tAverage reward:  212.89257648123777\n",
      "\tPercentage of positive rewards:  32.5 %\n",
      "\tNb times we recommended based on LightFM results:  273\n",
      "\tNb times the switch in predictions was a success:  31.135531135531135\n",
      "Test for margin: 1\t|======================================>|95%\n",
      "\tAverage reward:  195.70383298090158\n",
      "\tPercentage of positive rewards:  27.0 %\n",
      "\tNb times we recommended based on LightFM results:  230\n",
      "\tNb times the switch in predictions was a success:  22.608695652173914\n",
      "Test for margin: 1.5\t|======================================>|95%\n",
      "\tAverage reward:  168.80267799513533\n",
      "\tPercentage of positive rewards:  26.200000000000003 %\n",
      "\tNb times we recommended based on LightFM results:  554\n",
      "\tNb times the switch in predictions was a success:  27.79783393501805\n",
      "Test for margin: 2\t|======================================>|95%\n",
      "\tAverage reward:  129.62339979739562\n",
      "\tPercentage of positive rewards:  23.1 %\n",
      "\tNb times we recommended based on LightFM results:  772\n",
      "\tNb times the switch in predictions was a success:  22.797927461139896\n",
      "Test for margin: 2.5\t|======================================>|95%\n",
      "\tAverage reward:  108.08911179481099\n",
      "\tPercentage of positive rewards:  22.900000000000002 %\n",
      "\tNb times we recommended based on LightFM results:  846\n",
      "\tNb times the switch in predictions was a success:  24.349881796690305\n",
      "Test for margin: 3\t|======================================>|95%\n",
      "\tAverage reward:  110.22737259594653\n",
      "\tPercentage of positive rewards:  23.5 %\n",
      "\tNb times we recommended based on LightFM results:  862\n",
      "\tNb times the switch in predictions was a success:  23.665893271461716\n",
      "Test for margin: 3.5\t|======================================>|95%\n",
      "\tAverage reward:  91.52149443484106\n",
      "\tPercentage of positive rewards:  20.599999999999998 %\n",
      "\tNb times we recommended based on LightFM results:  823\n",
      "\tNb times the switch in predictions was a success:  21.628189550425272\n"
     ]
    }
   ],
   "source": [
    "for margin, model in zip(margins, models2):\n",
    "    rewards, nb_reward_pos,nb_switch,switch_success=0,0,0,0\n",
    "    mean,std = compute_price_norm(state_history)\n",
    "    k, max_k = 0, int(nb_iters / 50) # index just to print progrees\n",
    "    s = 'Test for margin: ' + str(margin)\n",
    "    end_ln = \"\\r\"\n",
    "    for i in range(nb_iters): \n",
    "        if i % 50 == 0:\n",
    "            if (max_k - k - 1 == 0): end_ln = \"\\n\"\n",
    "            print(s + \"\\t|\" + k * \"==\" +\">\"+ (max_k - k - 1) * \"--\" +\"|\" + str(int(i * 100/nb_iters)) + \"%\", end=end_ln)\n",
    "            k += 1\n",
    "        sleep(0.05) # sleep to let the API breathe and allow others to call requests\n",
    "\n",
    "        list_items = np.asarray(list(list(zip(*next_state))[1]))\n",
    "        if next_state[0][0] in pos_data.user_id.unique().tolist():\n",
    "            next_user = np.asarray([next_state[0][0] for i in range(len(next_state))])\n",
    "            next_userLFM = dict_users[next_state[0][0]]\n",
    "            list_feat_user = np.expand_dims(np.asarray([next_state[0][3:5] for i in range(len(next_state))]), axis=1)\n",
    "        else:\n",
    "            #predict items based on users' profile similarity \n",
    "            most_similar_user_id = compute_most_similar(state_history,next_state,pos_data) \n",
    "            next_user = np.asarray([most_similar_user_id for i in range(len(next_state))])\n",
    "            next_userLFM = dict_users[most_similar_user_id]\n",
    "            list_feat_user = list(pos_data.loc[pos_data.user_id==most_similar_user_id,'feat_users'])[0]\n",
    "            list_feat_user = np.expand_dims(np.asarray([list_feat_user for i in range(len(next_state))]), axis=1)\n",
    "\n",
    "\n",
    "        prices =list(list(zip(*next_state))[1])\n",
    "        feat_items = [next_state[0][5:-1] for i in range(len(next_state))]\n",
    "        prices_norm = [(price-mean)/std for price in prices ] \n",
    "\n",
    "        for i,feature in  enumerate(feat_items):\n",
    "            feature.append(prices_norm[i])\n",
    "\n",
    "        list_feat_items = np.expand_dims(np.asarray(feat_items), axis=1)\n",
    "\n",
    "        predictions = deep_match_model5.predict([next_user, list_items, list_feat_user, list_feat_items])\n",
    "        predictionsLFM = model_lightFM.predict(user_ids=next_userLFM, item_ids=list_items)\n",
    "        recommended_item = np.argmax(predictions)\n",
    "        recommended_itemLFM = np.argmax(predictionsLFM)\n",
    "\n",
    "        ## Recommend most expensive \n",
    "        if recommended_item != recommended_itemLFM:\n",
    "            if next_state[recommended_item][2] < next_state[recommended_itemLFM][2]:\n",
    "                recommended_item = recommended_itemLFM\n",
    "                nb_switch+=1\n",
    "\n",
    "        params['recommended_item'] = recommended_item \n",
    "        r=requests.get(url=url_predict,params=params)\n",
    "        d=r.json()\n",
    "        reward= d['reward'] # previous reward for the recommended item predicted\n",
    "        if reward > 0 : \n",
    "            nb_reward_pos+=1 \n",
    "            if recommended_item==recommended_itemLFM:\n",
    "                switch_success+=1\n",
    "\n",
    "        next_state = d['state']\n",
    "        rewards += reward\n",
    "    print('\\tAverage reward: ', rewards/nb_iters)\n",
    "    print('\\tPercentage of positive rewards: ', 100*(nb_reward_pos/nb_iters), '%')\n",
    "    print('\\tNb times we recommended based on LightFM results: ',nb_switch)\n",
    "    print('\\tNb times the switch in predictions was a success: ',100*(switch_success/nb_switch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{array}{|c|c|c|} \\hline\n",
    "   \\textbf{margin} & \\textbf{avg reward} & \\textbf{% of postitve} \\\\ \\hline\n",
    "   0.5 & \\textbf{212.89257648123777} & \\textbf{32.5}  \\\\ \n",
    "   1   & 195.70383298090158 & 27.0 \\\\\n",
    "   1.5 & 168.80267799513533 & 26.20  \\\\\n",
    "   2   & 129.62339979739562 & 23.1 \\\\\n",
    "   2.5 & 108.08911179481099 & 22.90 \\\\\n",
    "   3   & 110.22737259594653 & 23.5  \\\\\n",
    "   3.5 & 91.52149443484106 & 20.59  \\\\ \\hline\n",
    "\\end{array} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
